{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Logistic Regression </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Load the Data and Libraries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('DMV_Written_Tests.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 3 columns):\n",
      "DMV_Test_1    100 non-null float64\n",
      "DMV_Test_2    100 non-null float64\n",
      "Results       100 non-null int64\n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 2.4 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = data[['DMV_Test_1', 'DMV_Test_2']].values\n",
    "results = data['Results'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Visualize the Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# passed = (results == 1).reshape(100, 1)\n",
    "# failed = (results == 0).reshape(100, 1)\n",
    "\n",
    "# ax = sns.scatterplot(data=data, x=scores,y=results)\n",
    "# # ax = sns.scatterplot(x = scores[passed[:, 0], 0],\n",
    "# #                        y = scores[passed[:, 0], 1],\n",
    "# #                        marker = '^',\n",
    "# #                        color = ' green',\n",
    "# #                        s = 60)\n",
    "# #     sns.scatterplot(x = scores[failed[:, 0], 0],\n",
    "# #                        y = scores[failed[:, 0], 1],\n",
    "# #                        marker = 'x',\n",
    "# #                        color = ' red',\n",
    "# #                        s = 60)\n",
    "# ax.set(xlabel ='DMV Written test 1 score', ylabel = 'DMV Written test 2 score')\n",
    "# ax.lagend(['passed', 'failed'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Define the Logistic Sigmoid Function $\\sigma(z)$\n",
    "---\n",
    "\n",
    "$$ \\sigma(z) = \\frac{1}{1+e^{-z}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Compute the Cost Function $J(\\theta)$ and Gradient\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of logistic regression is to minimize the cost function\n",
    "\n",
    "$$J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} [ y^{(i)}log(h_{\\theta}(x^{(i)})) + (1 - y^{(i)})log(1 - (h_{\\theta}(x^{(i)}))]$$\n",
    "\n",
    "where the gradient of the cost function is given by\n",
    "\n",
    "$$ \\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^{m} (h_{\\theta}(x^{(i)}) - y^{(i)})x_j^{(i)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_compute(theta,x,y):\n",
    "    m = len(y)\n",
    "    h = sigmoid(np.dot(x, theta))\n",
    "    error = (y*np.log(h)) + (1-y)*np.log(1-h)\n",
    "    cost = -1/m * np.sum(error)\n",
    "    grad = 1/m * np.dot(x.transpose(), (h-y))\n",
    "    return cost, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Cost and Gradient at Initialization\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient before optimization process\n",
    "score_mean = np.mean(scores,axis=0)\n",
    "score_std = np.std(scores,axis=0)\n",
    "scores = (scores - score_mean)/score_std\n",
    "\n",
    "row = scores.shape[0]\n",
    "col = scores.shape[1]\n",
    "\n",
    "X = np.append(np.ones((row, 1)), scores, axis =1)\n",
    "y = results.reshape(row, 1)\n",
    "\n",
    "theta_init = np.zeros((col + 1, 1))\n",
    "cost, grad = cost_compute(theta_init, X, y)\n",
    "# score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at initialization 0.6931471805599453\n",
      "Gradient at initialization [[-0.1       ]\n",
      " [-0.28122914]\n",
      " [-0.25098615]]\n"
     ]
    }
   ],
   "source": [
    "print('Cost at initialization', cost)\n",
    "print('Gradient at initialization', grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = np.zeros((col+1, 1))\n",
    "# print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7: Gradient Descent\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimize the cost function $J(\\theta)$ by updating the below equation and repeat until convergence\n",
    "$\\theta_j := \\theta_j - \\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta_j}$ (simultaneously update $\\theta_j$ for all $j$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(theta, x, y, alpha, iteration):\n",
    "    costs = []\n",
    "    for i in range(iteration):\n",
    "        cost, grad = cost_compute(theta, x, y)\n",
    "        theta -= (alpha*grad)\n",
    "        costs.append(cost)\n",
    "    return theta, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, costs = gradient_descent(theta_init, X, y, 1, 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta after running  gradient descent [[1.71671348]\n",
      " [3.98908079]\n",
      " [3.72154954]]\n",
      "Resulting cost after optimization 0.20349778840675828\n"
     ]
    }
   ],
   "source": [
    "print('Theta after running  gradient descent', theta)\n",
    "print('Resulting cost after optimization', costs[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8: Plotting the Convergence of $J(\\theta)$\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot $J(\\theta)$ against the number of iterations of gradient descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9: Plotting the decision boundary\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$h_\\theta(x) = \\sigma(z)$, where $\\sigma$ is the logistic sigmoid function and $z = \\theta^Tx$\n",
    "\n",
    "When $h_\\theta(x) \\geq 0.5$ the model predicts class \"1\":\n",
    "\n",
    "$\\implies \\sigma(\\theta^Tx) \\geq 0.5$\n",
    "\n",
    "$\\implies \\theta^Tx \\geq 0$ predict class \"1\" \n",
    "\n",
    "Hence, $\\theta_1 + \\theta_2x_2 + \\theta_3x_3 = 0$ is the equation for the decision boundary, giving us \n",
    "\n",
    "$ x_3 = \\frac{-(\\theta_1+\\theta_2x_2)}{\\theta_3}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10: Predictions using the optimized $\\theta$ values\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$h_\\theta(x) = x\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
